# API Configuration
# For production, set this to your backend API URL (e.g., Hugging Face Spaces, Railway, Render)
NEXT_PUBLIC_API_URL=http://localhost:8000

# Better Auth Configuration
# For production, set NEXT_PUBLIC_AUTH_URL to your Vercel deployment URL (e.g., https://your-app.vercel.app)
NEXT_PUBLIC_AUTH_URL=http://localhost:3000
BETTER_AUTH_SECRET=your-shared-secret-here

# Database Configuration (for Better Auth user storage)
DATABASE_URL=postgresql://user:password@host:5432/database?sslmode=require

# Important: BETTER_AUTH_SECRET must match the backend secret exactly!

# =============================================================================
# Phase III: AI Chatbot Configuration
# =============================================================================

# Cohere API Key for LLM inference (intent analysis, response generation)
# Get your key from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=

# Cohere Model Selection
# Options: command-r-plus (best quality), command-r (faster, cheaper)
COHERE_MODEL=command-r-plus

# Agent Temperature Settings
# Lower = more deterministic, Higher = more creative
AGENT_INTENT_TEMPERATURE=0.3
AGENT_RESPONSE_TEMPERATURE=0.7

# Max tokens for agent responses
AGENT_MAX_TOKENS=1024

# Backend URL for API calls (Hugging Face Spaces or other deployment)
# This is used by the chatbot to make task API calls
BACKEND_URL=https://your-backend-url.hf.space
